{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "  input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "  input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a fashion_mnist model without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 805,194\n",
      "Trainable params: 805,130\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    l.Conv2D(\n",
    "        32, 5, padding='same', activation='relu', input_shape=input_shape),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.BatchNormalization(),\n",
    "    l.Flatten(input_shape=input_shape),\n",
    "    l.Dense(128, activation='relu'),\n",
    "    l.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 298us/sample - loss: 0.3645 - acc: 0.8704 - val_loss: 0.4892 - val_acc: 0.8652\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 0.2244 - acc: 0.9178 - val_loss: 0.2829 - val_acc: 0.8983\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 12s 194us/sample - loss: 0.1787 - acc: 0.9344 - val_loss: 0.2601 - val_acc: 0.9092\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 0.1407 - acc: 0.9475 - val_loss: 0.2864 - val_acc: 0.9074\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 219us/sample - loss: 0.1200 - acc: 0.9549 - val_loss: 0.3136 - val_acc: 0.9065\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 0.0972 - acc: 0.9638 - val_loss: 0.3924 - val_acc: 0.8939\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 0.0800 - acc: 0.9705 - val_loss: 0.3609 - val_acc: 0.9075\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.0715 - acc: 0.9750 - val_loss: 0.4236 - val_acc: 0.8973\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.0612 - acc: 0.9779 - val_loss: 0.4316 - val_acc: 0.9021\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 0.0556 - acc: 0.9798 - val_loss: 0.4387 - val_acc: 0.9068\n",
      "Test loss: 0.4387332788825035\n",
      "Test accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to:  /tmp/tmpps3xyecv.h5\n"
     ]
    }
   ],
   "source": [
    "# Backend agnostic way to save/restore models\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a pruned fashin_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End step: 4690\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "epochs = 10\n",
    "num_train_samples = x_train.shape[0]\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "print('End step: ' + str(end_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pierre/anaconda3/envs/ml-env/lib/python3.7/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.debugging.assert_greater_equal is deprecated. Please use tf.compat.v1.debugging.assert_greater_equal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309dd94c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309dd94c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309dd94c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309dd94c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/pierre/anaconda3/envs/ml-env/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/pierre/anaconda3/envs/ml-env/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py:59: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4d8a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4d8a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4d8a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4d8a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4df150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4df150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4df150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f309d4df150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d_1 (None, 28, 28, 32)        1634      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_8  (None, 128)               1605762   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_9  (None, 10)                2572      \n",
      "=================================================================\n",
      "Total params: 1,610,096\n",
      "Trainable params: 805,130\n",
      "Non-trainable params: 804,966\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.25,\n",
    "                                                   final_sparsity=0.75,\n",
    "                                                   begin_step=2000,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "}\n",
    "\n",
    "pruned_model = tf.keras.Sequential([\n",
    "    sparsity.prune_low_magnitude(\n",
    "        l.Conv2D(32, 5, padding='same', activation='relu'),\n",
    "        input_shape=input_shape,\n",
    "        **pruning_params),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.BatchNormalization(),\n",
    "    l.Flatten(),\n",
    "    sparsity.prune_low_magnitude(l.Dense(128, activation='relu'),\n",
    "                                 **pruning_params),\n",
    "    l.Dropout(0.4),\n",
    "    sparsity.prune_low_magnitude(l.Dense(num_classes, activation='softmax'),\n",
    "                                 **pruning_params)\n",
    "])\n",
    "\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training logs to /tmp/tmpmtxbdbap\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('Writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.7395 - acc: 0.7217INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 1.7393 - acc: 0.7219 - val_loss: 1.6345 - val_acc: 0.8318\n",
      "Epoch 2/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 1.5957 - acc: 0.8653INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 14s 226us/sample - loss: 1.5958 - acc: 0.8652 - val_loss: 1.5865 - val_acc: 0.8756\n",
      "Epoch 3/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5822 - acc: 0.8786INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 14s 233us/sample - loss: 1.5823 - acc: 0.8785 - val_loss: 1.5814 - val_acc: 0.8786\n",
      "Epoch 4/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 1.5732 - acc: 0.8875INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 1.5733 - acc: 0.8875 - val_loss: 1.5739 - val_acc: 0.8868\n",
      "Epoch 5/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 1.5671 - acc: 0.8939INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 15s 247us/sample - loss: 1.5671 - acc: 0.8939 - val_loss: 1.5683 - val_acc: 0.8915\n",
      "Epoch 6/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 1.5605 - acc: 0.9002INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 1.5605 - acc: 0.9001 - val_loss: 1.5655 - val_acc: 0.8955\n",
      "Epoch 7/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 1.5563 - acc: 0.9048INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 15s 245us/sample - loss: 1.5563 - acc: 0.9048 - val_loss: 1.5618 - val_acc: 0.8998\n",
      "Epoch 8/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5514 - acc: 0.9099INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 14s 233us/sample - loss: 1.5514 - acc: 0.9099 - val_loss: 1.5578 - val_acc: 0.9039\n",
      "Epoch 9/10\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 1.5489 - acc: 0.9121INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 1.5490 - acc: 0.9121 - val_loss: 1.5613 - val_acc: 0.9001\n",
      "Epoch 10/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 1.5451 - acc: 0.9161INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/mask:0/sparsity is illegal; using prune_low_magnitude_dense_8/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/mask:0/sparsity is illegal; using prune_low_magnitude_dense_9/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_8/threshold:0/threshold is illegal; using prune_low_magnitude_dense_8/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_9/threshold:0/threshold is illegal; using prune_low_magnitude_dense_9/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 1.5451 - acc: 0.9162 - val_loss: 1.5673 - val_acc: 0.8932\n",
      "Test loss: 1.5672730331420899\n",
      "Test accuracy: 0.8932\n"
     ]
    }
   ],
   "source": [
    "pruned_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
    "# step. Also add a callback to add pruning summaries to tensorboard\n",
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]\n",
    "\n",
    "pruned_model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = pruned_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 805,194\n",
      "Trainable params: 805,130\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = sparsity.strip_pruning(pruned_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  /tmp/tmpbvifc2ik.h5\n"
     ]
    }
   ],
   "source": [
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', pruned_keras_file)\n",
    "\n",
    "# No need to save the optimizer with the graph for serving.\n",
    "tf.keras.models.save_model(final_model, pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the size of the unpruned vs. pruned model after compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unpruned model before compression: 3.09 Mb\n",
      "Size of the unpruned model after compression: 2.86 Mb\n",
      "Size of the pruned model before compression: 3.09 Mb\n",
      "Size of the pruned model after compression: 1.78 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip1 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(keras_file)\n",
    "print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(keras_file) / float(2**20)))\n",
    "print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip1) / float(2**20)))\n",
    "\n",
    "_, zip2 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip2, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(pruned_keras_file)\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip2) / float(2**20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
