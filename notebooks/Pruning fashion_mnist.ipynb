{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "  input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "  input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a fashion_mnist model without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 805,194\n",
      "Trainable params: 805,130\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    l.Conv2D(\n",
    "        32, 5, padding='same', activation='relu', input_shape=input_shape),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.BatchNormalization(),\n",
    "    l.Flatten(input_shape=input_shape),\n",
    "    l.Dense(128, activation='relu'),\n",
    "    l.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 298us/sample - loss: 0.3645 - acc: 0.8704 - val_loss: 0.4892 - val_acc: 0.8652\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 0.2244 - acc: 0.9178 - val_loss: 0.2829 - val_acc: 0.8983\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 12s 194us/sample - loss: 0.1787 - acc: 0.9344 - val_loss: 0.2601 - val_acc: 0.9092\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 0.1407 - acc: 0.9475 - val_loss: 0.2864 - val_acc: 0.9074\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 219us/sample - loss: 0.1200 - acc: 0.9549 - val_loss: 0.3136 - val_acc: 0.9065\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 0.0972 - acc: 0.9638 - val_loss: 0.3924 - val_acc: 0.8939\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 0.0800 - acc: 0.9705 - val_loss: 0.3609 - val_acc: 0.9075\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s 235us/sample - loss: 0.0715 - acc: 0.9750 - val_loss: 0.4236 - val_acc: 0.8973\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s 203us/sample - loss: 0.0612 - acc: 0.9779 - val_loss: 0.4316 - val_acc: 0.9021\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 0.0556 - acc: 0.9798 - val_loss: 0.4387 - val_acc: 0.9068\n",
      "Test loss: 0.4387332788825035\n",
      "Test accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to:  /tmp/tmpps3xyecv.h5\n"
     ]
    }
   ],
   "source": [
    "# Backend agnostic way to save/restore models\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a pruned fashin_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End step: 4690\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "epochs = 10\n",
    "num_train_samples = x_train.shape[0]\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "print('End step: ' + str(end_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097323d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097329490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097329490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097329490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f3097329490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d_3 (None, 28, 28, 32)        1634      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_12 (None, 128)               1605762   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_13 (None, 10)                2572      \n",
      "=================================================================\n",
      "Total params: 1,610,096\n",
      "Trainable params: 805,130\n",
      "Non-trainable params: 804,966\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.25,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=2000,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "}\n",
    "\n",
    "pruned_model = tf.keras.Sequential([\n",
    "    sparsity.prune_low_magnitude(\n",
    "        l.Conv2D(32, 5, padding='same', activation='relu'),\n",
    "        input_shape=input_shape,\n",
    "        **pruning_params),\n",
    "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    l.BatchNormalization(),\n",
    "    l.Flatten(),\n",
    "    sparsity.prune_low_magnitude(l.Dense(128, activation='relu'),\n",
    "                                 **pruning_params),\n",
    "    l.Dropout(0.4),\n",
    "    sparsity.prune_low_magnitude(l.Dense(num_classes, activation='softmax'),\n",
    "                                 **pruning_params)\n",
    "])\n",
    "\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training logs to /tmp/tmppezqd_oe\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('Writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.6534 - acc: 0.8078INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 1.6533 - acc: 0.8080 - val_loss: 1.6131 - val_acc: 0.8522\n",
      "Epoch 2/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5924 - acc: 0.8687INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 15s 249us/sample - loss: 1.5923 - acc: 0.8687 - val_loss: 1.5881 - val_acc: 0.8718\n",
      "Epoch 3/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5805 - acc: 0.8803INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 13s 221us/sample - loss: 1.5806 - acc: 0.8802 - val_loss: 1.5786 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5730 - acc: 0.8876INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 15s 253us/sample - loss: 1.5730 - acc: 0.8877 - val_loss: 1.5804 - val_acc: 0.8802\n",
      "Epoch 5/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5663 - acc: 0.8942- ETA: 0s - loss: 1.5662 - INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 15s 252us/sample - loss: 1.5662 - acc: 0.8943 - val_loss: 1.5708 - val_acc: 0.8908\n",
      "Epoch 6/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5646 - acc: 0.8968INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 17s 286us/sample - loss: 1.5646 - acc: 0.8969 - val_loss: 1.5768 - val_acc: 0.8851\n",
      "Epoch 7/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5699 - acc: 0.8932INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 15s 257us/sample - loss: 1.5699 - acc: 0.8932 - val_loss: 1.5706 - val_acc: 0.8913\n",
      "Epoch 8/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5801 - acc: 0.8855INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 14s 231us/sample - loss: 1.5801 - acc: 0.8855 - val_loss: 1.5807 - val_acc: 0.8795\n",
      "Epoch 9/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 1.5867 - acc: 0.8815INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 1.5867 - acc: 0.8815 - val_loss: 1.5770 - val_acc: 0.8849\n",
      "Epoch 10/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 1.5796 - acc: 0.8875INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/mask:0/sparsity is illegal; using prune_low_magnitude_dense_12/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/mask:0/sparsity is illegal; using prune_low_magnitude_dense_13/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_12/threshold:0/threshold is illegal; using prune_low_magnitude_dense_12/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_13/threshold:0/threshold is illegal; using prune_low_magnitude_dense_13/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 1.5795 - acc: 0.8875 - val_loss: 1.5669 - val_acc: 0.8950\n",
      "Test loss: 1.566889686012268\n",
      "Test accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "pruned_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
    "# step. Also add a callback to add pruning summaries to tensorboard\n",
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]\n",
    "\n",
    "pruned_model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = pruned_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 805,194\n",
      "Trainable params: 805,130\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = sparsity.strip_pruning(pruned_model)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  /tmp/tmpnu8ph786.h5\n"
     ]
    }
   ],
   "source": [
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', pruned_keras_file)\n",
    "\n",
    "# No need to save the optimizer with the graph for serving.\n",
    "tf.keras.models.save_model(final_model, pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the size of the unpruned vs. pruned model after compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unpruned model before compression: 3.09 Mb\n",
      "Size of the unpruned model after compression: 2.86 Mb\n",
      "Size of the pruned model before compression: 3.09 Mb\n",
      "Size of the pruned model after compression: 0.60 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip1 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(keras_file)\n",
    "print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(keras_file) / float(2**20)))\n",
    "print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip1) / float(2**20)))\n",
    "\n",
    "_, zip2 = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip2, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(pruned_keras_file)\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" % \n",
    "      (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" % \n",
    "      (os.path.getsize(zip2) / float(2**20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
